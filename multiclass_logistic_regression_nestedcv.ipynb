{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, det_curve\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold, GridSearchCV\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../data'\n",
    "clincopathology = pd.read_csv(os.path.join(DATA_ROOT, 'clincopathology_features.csv'))\n",
    "clinical = pd.read_csv(os.path.join(DATA_ROOT, 'clinical_features.csv'))\n",
    "pathology = pd.read_csv(os.path.join(DATA_ROOT, 'pathology_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_features = clinical.drop(columns=['pid', 'diagnosis'])\n",
    "pathology_features = pathology.drop(columns=['pid', 'diagnosis'])\n",
    "clincopathology_features = clincopathology.drop(columns=['pid', 'diagnosis'])\n",
    "outcomes = clinical['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4e2e5",
   "metadata": {},
   "source": [
    "## Multiclass Logistic Regression with nested CV, return best outcome with the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_multiclass_lr_cv(features, outcomes):\n",
    "    # outer loop: 10-fold cv \n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # define hyperparams for grid search \n",
    "    param_grid = {\n",
    "        'logisticregression__C': [0.1, 1, 10],  # regularization strength\n",
    "        'logisticregression__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "\n",
    "    # Initialize metrics lists\n",
    "    outer_f1_scores = []  # weighted F1 score per fold (weighted by the number of samples)\n",
    "    class_f1_scores = {cls: [] for cls in np.unique(outcomes)}  # per-class F1 scores\n",
    "\n",
    "    # track predictions for confusion matrix \n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    # define outer cv loop for performance evaluation\n",
    "    for train_index, test_index in outer_cv.split(features, outcomes):\n",
    "        X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        y_train, y_test = outcomes.iloc[train_index], outcomes.iloc[test_index]\n",
    "\n",
    "        # define inner cv loop for hyperparam tuning \n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # define model pipeline \n",
    "        pipeline = make_pipeline(\n",
    "            KNNImputer(n_neighbors=5, weights='distance'),\n",
    "            StandardScaler(),\n",
    "            LogisticRegression( # multinomial lr automatically chosen \n",
    "                solver=\"saga\",  # supports both l1 and l2 and multinomidal\n",
    "                max_iter=500,\n",
    "                random_state=42\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # grid search for inner cv loop \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=inner_cv, scoring='f1_weighted', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # re-train model using X_train and the best hyperparameters found during grid search \n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # get predictions on X_test\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "        # track predictions and true labels for entire dataset tracking\n",
    "        # (used to contruct a confusion matrix after the outer cv loop) \n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "\n",
    "        # fold f1-scores \n",
    "        fold_class_f1_scores = f1_score(y_test, y_pred, average=None, labels=np.unique(outcomes))\n",
    "        for cls, f1 in zip(np.unique(outcomes), fold_class_f1_scores):\n",
    "            class_f1_scores[cls].append(f1)\n",
    "\n",
    "        fold_weighted_f1 = f1_score(y_test, y_pred, average='weighted') # weighted sum of per-class f1-score, weighted by number of samples\n",
    "        outer_f1_scores.append(fold_weighted_f1)\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(outcomes))\n",
    "    report = classification_report(all_y_true, all_y_pred, target_names=[str(cls) for cls in np.unique(outcomes)])\n",
    "\n",
    "    print(\"Weighted F1 Scores across folds:\", outer_f1_scores)\n",
    "    print(f\"Average Weighted F1 Score (Sd): {np.mean(outer_f1_scores):.3f} ({np.std(outer_f1_scores):.3f})\")\n",
    "    print(\"Per-Class Average F1 Scores (SD):\")\n",
    "    for cls in class_f1_scores:\n",
    "        print(f\"Class {cls}: {np.mean(class_f1_scores[cls]):.3f} ({np.std(class_f1_scores[cls]):.3f})\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_multiclass_lr_cv_late_fusion_with_weights(clinical_features, pathology_features, outcomes):\n",
    "    # outer loop: 10-fold cv \n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # define hyperparam for grid search \n",
    "    param_grid = {\n",
    "        'logisticregression__C': [0.1, 1, 10],  # reg strength\n",
    "        'logisticregression__penalty': ['l1', 'l2'],\n",
    "        'fusion_weight': [[0.5, 0.5], [0.6, 0.4], [0.4, 0.6], [0.7, 0.3], [0.3, 0.7]]  # weighing two single-modality models \n",
    "    }\n",
    "\n",
    "    # track metrics \n",
    "    outer_f1_scores = []  # Weighted F1 score per fold (weighted by the number of samples)\n",
    "    class_f1_scores = {cls: [] for cls in np.unique(outcomes)}  # Per-class F1 scores\n",
    "\n",
    "    # track predictions for confusion matrix \n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    for train_index, test_index in outer_cv.split(clinical_features, outcomes):\n",
    "        X_train_clinical, X_test_clinical = clinical_features.iloc[train_index], clinical_features.iloc[test_index]\n",
    "        X_train_pathology, X_test_pathology = pathology_features.iloc[train_index], pathology_features.iloc[test_index]\n",
    "        y_train, y_test = outcomes.iloc[train_index], outcomes.iloc[test_index]\n",
    "\n",
    "        # inner cv\n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # clinical-only model pipeline \n",
    "        clinical_pipeline = make_pipeline(\n",
    "            KNNImputer(n_neighbors=5, weights='distance'),\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(\n",
    "                solver=\"saga\",\n",
    "                max_iter=500,\n",
    "                random_state=42\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # pathology-only model pipeline \n",
    "        pathology_pipeline = make_pipeline(\n",
    "            KNNImputer(n_neighbors=5, weights='distance'),\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(\n",
    "                solver=\"saga\",\n",
    "                max_iter=500,\n",
    "                random_state=42\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # git\n",
    "        clinical_pipeline.fit(X_train_clinical, y_train)\n",
    "        pathology_pipeline.fit(X_train_pathology, y_train)\n",
    "\n",
    "        # get pred prob\n",
    "        clinical_proba = clinical_pipeline.predict_proba(X_test_clinical)\n",
    "        pathology_proba = pathology_pipeline.predict_proba(X_test_pathology)\n",
    "\n",
    "        # inner loop grid search \n",
    "        best_score = -np.inf\n",
    "        best_weight = None\n",
    "        best_params = None\n",
    "\n",
    "        for fusion_weight in param_grid['fusion_weight']:\n",
    "            for penalty in ['l1', 'l2']:\n",
    "                for C in [0.1, 1, 10]:\n",
    "                    # Apply weight combination\n",
    "                    combined_proba = fusion_weight[0] * clinical_proba + fusion_weight[1] * pathology_proba\n",
    "                    unique_classes = np.unique(outcomes)\n",
    "                    predicted_indices = np.argmax(combined_proba, axis=1)\n",
    "                    y_pred = unique_classes[predicted_indices]\n",
    "\n",
    "                    # eval by f1 score \n",
    "                    fold_score = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "                    if fold_score > best_score:\n",
    "                        best_score = fold_score\n",
    "                        best_weight = fusion_weight\n",
    "                        best_params = {'C': C, 'penalty': penalty}\n",
    "\n",
    "        # final predictions using the best hyperparams \n",
    "        combined_proba = best_weight[0] * clinical_proba + best_weight[1] * pathology_proba\n",
    "        unique_classes = np.unique(outcomes)\n",
    "        predicted_indices = np.argmax(combined_proba, axis=1)\n",
    "        y_pred = unique_classes[predicted_indices]\n",
    "\n",
    "        # track predictions \n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "\n",
    "        # Fold F1 scores\n",
    "        fold_class_f1_scores = f1_score(y_test, y_pred, average=None, labels=np.unique(outcomes))\n",
    "        for cls, f1 in zip(np.unique(outcomes), fold_class_f1_scores):\n",
    "            class_f1_scores[cls].append(f1)\n",
    "\n",
    "        fold_weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        outer_f1_scores.append(fold_weighted_f1)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    conf_matrix = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(outcomes))\n",
    "    report = classification_report(\n",
    "        all_y_true, all_y_pred,\n",
    "        target_names=[str(cls) for cls in np.unique(outcomes)]\n",
    "    )\n",
    "\n",
    "    print(\"Weighted F1 Scores across folds:\", outer_f1_scores)\n",
    "    print(f\"Average Weighted F1 Score (SD): {np.mean(outer_f1_scores):.3f} ({np.std(outer_f1_scores):.3f})\")\n",
    "    print(\"Per-Class Average F1 Scores (SD):\")\n",
    "    for cls in class_f1_scores:\n",
    "        print(f\"Class {cls}: {np.mean(class_f1_scores[cls]):.3f} ({np.std(class_f1_scores[cls]):.3f})\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d811ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_conf = nested_multiclass_lr_cv(clinical_features, outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d678092",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_conf = nested_multiclass_lr_cv(pathology_features, outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c424b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_conf = nested_multiclass_lr_cv(clincopathology_features, outcomes) # early-fusion confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_matrix = nested_multiclass_lr_cv_late_fusion(clinical_features, pathology_features, outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2699a7-40c3-4059-a86d-c1ab481d7950",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix, class_names, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using matplotlib.\n",
    "\n",
    "    Parameters:\n",
    "    - conf_matrix (array-like): Confusion matrix (2D array).\n",
    "    - class_names (list): List of class names corresponding to the confusion matrix indices.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    im = ax.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
    "    # ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set(xticks=np.arange(conf_matrix.shape[1]),\n",
    "           yticks=np.arange(conf_matrix.shape[0]),\n",
    "           xticklabels=class_names, yticklabels=class_names)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(\"Predicted Label\", fontsize=16)\n",
    "    ax.set_ylabel(\"True Label\", fontsize=16)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357a864-0919-47d1-bf02-8776985b10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [str(cls) for cls in np.unique(outcomes)]\n",
    "class_names_str = [\n",
    "    'psoriasis',\n",
    "    'seboreic dermatitis',\n",
    "    'lichen planus',\n",
    "    'pityriasis rosea',\n",
    "    'cronic dermatitis',\n",
    "    'pityriasis rubra pilaris',\n",
    "]\n",
    "\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(c_conf, class_names_str, 'Clinical-only model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12a90a-7b3f-4af7-a59c-0a667475a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(ef_conf, class_names_str, 'Early-fusion model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995dfe9-96d9-4f7b-bd23-51f452b8c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lf_matrix, class_names_str, 'late-fusion model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8ccea-1d48-4c92-b18f-b168d4949017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d18142-8895-493f-8941-caf210963319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misc",
   "language": "python",
   "name": "misc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
